{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fall 2024 Data Science Track: Week 2 - Data Cleaning Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packages, Packages, Packages!\n",
    "\n",
    "Import *all* the things here! You need the standard stuff: `pandas` and `numpy`.\n",
    "\n",
    "If you got more stuff you want to use, add them here too. 🙂"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import here.\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "With the packages out of the way, now you will be working with the following data sets:\n",
    "\n",
    "* `food_coded.csv`: [Food choices](https://www.kaggle.com/datasets/borapajo/food-choices?select=food_coded.csv) from Kaggle\n",
    "* `Ask A Manager Salary Survey 2021 (Responses) - Form Responses 1.tsv`: [Ask A Manager Salary Survey 2021 (Responses)](https://docs.google.com/spreadsheets/d/1IPS5dBSGtwYVbjsfbaMCYIWnOuRmJcbequohNxCyGVw/view?&gid=1625408792) as *Tab Separated Values (.tsv)* from Google Docs\n",
    "\n",
    "Each one poses different challenges. But you’ll―of course―overcome them with what you learned in class! 😉"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Food Choices Data Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Food choices data set into a variable (e.g., df_food).\n",
    "\n",
    "food_data_set_path = 'data/food_coded.csv'\n",
    "\n",
    "df_food = pd.read_csv(food_data_set_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How much data did you just load? <br>\n",
    "<b> Answer: (125, 61) -> 125 Rows and 61 Columns/Features </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(125, 61)"
      ]
     },
     "execution_count": 450,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count by hand. (lol kidding)\n",
    "df_food.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are the columns and their types in this data set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column: GPA, Type: object\n",
      "Column: Gender, Type: int64\n",
      "Column: breakfast, Type: int64\n",
      "Column: calories_chicken, Type: int64\n",
      "Column: calories_day, Type: float64\n",
      "Column: calories_scone, Type: float64\n",
      "Column: coffee, Type: int64\n",
      "Column: comfort_food, Type: object\n",
      "Column: comfort_food_reasons, Type: object\n",
      "Column: comfort_food_reasons_coded, Type: float64\n",
      "Column: cook, Type: float64\n",
      "Column: comfort_food_reasons_coded.1, Type: int64\n",
      "Column: cuisine, Type: float64\n",
      "Column: diet_current, Type: object\n",
      "Column: diet_current_coded, Type: int64\n",
      "Column: drink, Type: float64\n",
      "Column: eating_changes, Type: object\n",
      "Column: eating_changes_coded, Type: int64\n",
      "Column: eating_changes_coded1, Type: int64\n",
      "Column: eating_out, Type: int64\n",
      "Column: employment, Type: float64\n",
      "Column: ethnic_food, Type: int64\n",
      "Column: exercise, Type: float64\n",
      "Column: father_education, Type: float64\n",
      "Column: father_profession, Type: object\n",
      "Column: fav_cuisine, Type: object\n",
      "Column: fav_cuisine_coded, Type: int64\n",
      "Column: fav_food, Type: float64\n",
      "Column: food_childhood, Type: object\n",
      "Column: fries, Type: int64\n",
      "Column: fruit_day, Type: int64\n",
      "Column: grade_level, Type: int64\n",
      "Column: greek_food, Type: int64\n",
      "Column: healthy_feeling, Type: int64\n",
      "Column: healthy_meal, Type: object\n",
      "Column: ideal_diet, Type: object\n",
      "Column: ideal_diet_coded, Type: int64\n",
      "Column: income, Type: float64\n",
      "Column: indian_food, Type: int64\n",
      "Column: italian_food, Type: int64\n",
      "Column: life_rewarding, Type: float64\n",
      "Column: marital_status, Type: float64\n",
      "Column: meals_dinner_friend, Type: object\n",
      "Column: mother_education, Type: float64\n",
      "Column: mother_profession, Type: object\n",
      "Column: nutritional_check, Type: int64\n",
      "Column: on_off_campus, Type: float64\n",
      "Column: parents_cook, Type: int64\n",
      "Column: pay_meal_out, Type: int64\n",
      "Column: persian_food, Type: float64\n",
      "Column: self_perception_weight, Type: float64\n",
      "Column: soup, Type: float64\n",
      "Column: sports, Type: float64\n",
      "Column: thai_food, Type: int64\n",
      "Column: tortilla_calories, Type: float64\n",
      "Column: turkey_calories, Type: int64\n",
      "Column: type_sports, Type: object\n",
      "Column: veggies_day, Type: int64\n",
      "Column: vitamins, Type: int64\n",
      "Column: waffle_calories, Type: int64\n",
      "Column: weight, Type: object\n"
     ]
    }
   ],
   "source": [
    "# Show the column names and their types.\n",
    "names_and_types = {}\n",
    "# Manually print so it does not get truncated\n",
    "for column, type in zip(df_food, df_food.dtypes):\n",
    "    names_and_types[column] = type\n",
    "\n",
    "for key_value in names_and_types:\n",
    "    print(f\"Column: {key_value}, Type: {names_and_types[key_value]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean the Data\n",
    "\n",
    "Perhaps we’d like to know more another day, but the team is really interested in just the relationship between calories (`calories_day`) and weight. …and maybe gender."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you remove the other columns?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>calories_day</th>\n",
       "      <th>weight</th>\n",
       "      <th>Gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>187</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>I'm not answering this.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>Not sure, 240</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>190</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>4.0</td>\n",
       "      <td>156</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>2.0</td>\n",
       "      <td>180</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>NaN</td>\n",
       "      <td>120</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>4.0</td>\n",
       "      <td>135</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>NaN</td>\n",
       "      <td>135</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>125 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     calories_day                    weight  Gender\n",
       "0             NaN                       187       2\n",
       "1             3.0                       155       1\n",
       "2             4.0  I'm not answering this.        1\n",
       "3             3.0             Not sure, 240       1\n",
       "4             2.0                       190       1\n",
       "..            ...                       ...     ...\n",
       "120           4.0                       156       1\n",
       "121           2.0                       180       1\n",
       "122           NaN                       120       1\n",
       "123           4.0                       135       2\n",
       "124           NaN                       135       1\n",
       "\n",
       "[125 rows x 3 columns]"
      ]
     },
     "execution_count": 452,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove ‘em.\n",
    "columns_to_keep = [\"calories_day\", \"weight\", \"Gender\"]\n",
    "\n",
    "df_food_filtered = df_food.loc[:, columns_to_keep]\n",
    "df_food_filtered\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What about `NaN`s? How many are there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "calories_day    19\n",
       "weight           2\n",
       "Gender           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 453,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count ‘em.\n",
    "df_food_filtered.isna().sum()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We gotta remove those `NaN`s―the entire row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop ‘em.\n",
    "df_food_filtered = df_food_filtered.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "calories_day    0\n",
       "weight          0\n",
       "Gender          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 455,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_food_filtered\n",
    "df_food_filtered.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But what about the weird non-numeric values in the column obviously meant for numeric data?\n",
    "\n",
    "Notice the data type of that column from when you got the types of all the columns?\n",
    "\n",
    "If only we could convert the column to a numeric type and drop the rows with invalid values. 🤔"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix that.\n",
    "df_food_filtered.at[3, 'weight'] = float(240)\n",
    "# Drop Column where weight has the value \"I don't want to answer that.' \"\n",
    "df_food_filtered = df_food_filtered.drop(2, axis=0)\n",
    "# Remove entries with 'lbs' in the unit\n",
    "df_food_filtered['weight'] = df_food_filtered['weight'].str.replace(' lbs', '').astype(float)\n",
    "\n",
    "# Convert dtypes\n",
    "df_food_filtered.astype({\n",
    "    'calories_day' : float,\n",
    "    'Gender' : int,\n",
    "    'weight' : float\n",
    "})\n",
    "\n",
    "# Fix the row with 'weight' column entry = \"'Not sure, 240\" to just 240\n",
    "df_food_filtered.at[3, 'weight'] = float(240)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "calories_day    float64\n",
       "weight          float64\n",
       "Gender            int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 457,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_food_filtered.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>calories_day</th>\n",
       "      <th>weight</th>\n",
       "      <th>Gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3.0</td>\n",
       "      <td>264.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    calories_day  weight  Gender\n",
       "1            3.0   155.0       1\n",
       "3            3.0   240.0       1\n",
       "4            2.0   190.0       1\n",
       "5            3.0   190.0       1\n",
       "6            3.0   180.0       2\n",
       "7            3.0   137.0       1\n",
       "9            3.0   125.0       1\n",
       "10           3.0   116.0       1\n",
       "11           4.0   110.0       1\n",
       "12           3.0   264.0       2"
      ]
     },
     "execution_count": 458,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_food_filtered.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now this data seems reasonably clean for our purposes! 😁\n",
    "\n",
    "Let’s save it somewhere to be shipped off to another teammate. 💾"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Savey save!\n",
    "df_food_filtered.to_csv('data/cleaned_food_coded.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ask a Manager Salary Survey 2021 (Responses) Data Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>How old are you?</th>\n",
       "      <th>What industry do you work in?</th>\n",
       "      <th>Job title</th>\n",
       "      <th>If your job title needs additional context, please clarify here:</th>\n",
       "      <th>What is your annual salary? (You'll indicate the currency in a later question. If you are part-time or hourly, please enter an annualized equivalent -- what you would earn if you worked the job 40 hours a week, 52 weeks a year.)</th>\n",
       "      <th>How much additional monetary compensation do you get, if any (for example, bonuses or overtime in an average year)? Please only include monetary compensation here, not the value of benefits.</th>\n",
       "      <th>Please indicate the currency</th>\n",
       "      <th>If \"Other,\" please indicate the currency here:</th>\n",
       "      <th>If your income needs additional context, please provide it here:</th>\n",
       "      <th>What country do you work in?</th>\n",
       "      <th>If you're in the U.S., what state do you work in?</th>\n",
       "      <th>What city do you work in?</th>\n",
       "      <th>How many years of professional work experience do you have overall?</th>\n",
       "      <th>How many years of professional work experience do you have in your field?</th>\n",
       "      <th>What is your highest level of education completed?</th>\n",
       "      <th>What is your gender?</th>\n",
       "      <th>What is your race? (Choose all that apply.)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4/27/2021 11:02:10</td>\n",
       "      <td>25-34</td>\n",
       "      <td>Education (Higher Education)</td>\n",
       "      <td>Research and Instruction Librarian</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55,000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United States</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>Boston</td>\n",
       "      <td>5-7 years</td>\n",
       "      <td>5-7 years</td>\n",
       "      <td>Master's degree</td>\n",
       "      <td>Woman</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4/27/2021 11:02:22</td>\n",
       "      <td>25-34</td>\n",
       "      <td>Computing or Tech</td>\n",
       "      <td>Change &amp; Internal Communications Manager</td>\n",
       "      <td>NaN</td>\n",
       "      <td>54,600</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>GBP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cambridge</td>\n",
       "      <td>8 - 10 years</td>\n",
       "      <td>5-7 years</td>\n",
       "      <td>College degree</td>\n",
       "      <td>Non-binary</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4/27/2021 11:02:38</td>\n",
       "      <td>25-34</td>\n",
       "      <td>Accounting, Banking &amp; Finance</td>\n",
       "      <td>Marketing Specialist</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34,000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>Tennessee</td>\n",
       "      <td>Chattanooga</td>\n",
       "      <td>2 - 4 years</td>\n",
       "      <td>2 - 4 years</td>\n",
       "      <td>College degree</td>\n",
       "      <td>Woman</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4/27/2021 11:02:41</td>\n",
       "      <td>25-34</td>\n",
       "      <td>Nonprofits</td>\n",
       "      <td>Program Manager</td>\n",
       "      <td>NaN</td>\n",
       "      <td>62,000</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>USA</td>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>Milwaukee</td>\n",
       "      <td>8 - 10 years</td>\n",
       "      <td>5-7 years</td>\n",
       "      <td>College degree</td>\n",
       "      <td>Woman</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4/27/2021 11:02:42</td>\n",
       "      <td>25-34</td>\n",
       "      <td>Accounting, Banking &amp; Finance</td>\n",
       "      <td>Accounting Manager</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60,000</td>\n",
       "      <td>7000.0</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>South Carolina</td>\n",
       "      <td>Greenville</td>\n",
       "      <td>8 - 10 years</td>\n",
       "      <td>5-7 years</td>\n",
       "      <td>College degree</td>\n",
       "      <td>Woman</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Timestamp How old are you?  What industry do you work in?  \\\n",
       "0  4/27/2021 11:02:10            25-34   Education (Higher Education)   \n",
       "1  4/27/2021 11:02:22            25-34              Computing or Tech   \n",
       "2  4/27/2021 11:02:38            25-34  Accounting, Banking & Finance   \n",
       "3  4/27/2021 11:02:41            25-34                     Nonprofits   \n",
       "4  4/27/2021 11:02:42            25-34  Accounting, Banking & Finance   \n",
       "\n",
       "                                  Job title  \\\n",
       "0        Research and Instruction Librarian   \n",
       "1  Change & Internal Communications Manager   \n",
       "2                      Marketing Specialist   \n",
       "3                           Program Manager   \n",
       "4                        Accounting Manager   \n",
       "\n",
       "  If your job title needs additional context, please clarify here:  \\\n",
       "0                                                NaN                 \n",
       "1                                                NaN                 \n",
       "2                                                NaN                 \n",
       "3                                                NaN                 \n",
       "4                                                NaN                 \n",
       "\n",
       "  What is your annual salary? (You'll indicate the currency in a later question. If you are part-time or hourly, please enter an annualized equivalent -- what you would earn if you worked the job 40 hours a week, 52 weeks a year.)  \\\n",
       "0                                             55,000                                                                                                                                                                                     \n",
       "1                                             54,600                                                                                                                                                                                     \n",
       "2                                             34,000                                                                                                                                                                                     \n",
       "3                                             62,000                                                                                                                                                                                     \n",
       "4                                             60,000                                                                                                                                                                                     \n",
       "\n",
       "   How much additional monetary compensation do you get, if any (for example, bonuses or overtime in an average year)? Please only include monetary compensation here, not the value of benefits.  \\\n",
       "0                                                0.0                                                                                                                                                \n",
       "1                                             4000.0                                                                                                                                                \n",
       "2                                                NaN                                                                                                                                                \n",
       "3                                             3000.0                                                                                                                                                \n",
       "4                                             7000.0                                                                                                                                                \n",
       "\n",
       "  Please indicate the currency  \\\n",
       "0                          USD   \n",
       "1                          GBP   \n",
       "2                          USD   \n",
       "3                          USD   \n",
       "4                          USD   \n",
       "\n",
       "  If \"Other,\" please indicate the currency here:   \\\n",
       "0                                             NaN   \n",
       "1                                             NaN   \n",
       "2                                             NaN   \n",
       "3                                             NaN   \n",
       "4                                             NaN   \n",
       "\n",
       "  If your income needs additional context, please provide it here:  \\\n",
       "0                                                NaN                 \n",
       "1                                                NaN                 \n",
       "2                                                NaN                 \n",
       "3                                                NaN                 \n",
       "4                                                NaN                 \n",
       "\n",
       "  What country do you work in?  \\\n",
       "0                United States   \n",
       "1               United Kingdom   \n",
       "2                           US   \n",
       "3                          USA   \n",
       "4                           US   \n",
       "\n",
       "  If you're in the U.S., what state do you work in? What city do you work in?  \\\n",
       "0                                     Massachusetts                    Boston   \n",
       "1                                               NaN                 Cambridge   \n",
       "2                                         Tennessee               Chattanooga   \n",
       "3                                         Wisconsin                 Milwaukee   \n",
       "4                                    South Carolina                Greenville   \n",
       "\n",
       "  How many years of professional work experience do you have overall?  \\\n",
       "0                                          5-7 years                    \n",
       "1                                       8 - 10 years                    \n",
       "2                                        2 - 4 years                    \n",
       "3                                       8 - 10 years                    \n",
       "4                                       8 - 10 years                    \n",
       "\n",
       "  How many years of professional work experience do you have in your field?  \\\n",
       "0                                          5-7 years                          \n",
       "1                                          5-7 years                          \n",
       "2                                        2 - 4 years                          \n",
       "3                                          5-7 years                          \n",
       "4                                          5-7 years                          \n",
       "\n",
       "  What is your highest level of education completed? What is your gender?  \\\n",
       "0                                    Master's degree                Woman   \n",
       "1                                     College degree           Non-binary   \n",
       "2                                     College degree                Woman   \n",
       "3                                     College degree                Woman   \n",
       "4                                     College degree                Woman   \n",
       "\n",
       "  What is your race? (Choose all that apply.)  \n",
       "0                                       White  \n",
       "1                                       White  \n",
       "2                                       White  \n",
       "3                                       White  \n",
       "4                                       White  "
      ]
     },
     "execution_count": 460,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the Ask A Manager Salary Survey 2021 (Responses) data set into a variable (e.g., df_salary).\n",
    "df_salary = pd.read_csv('data/manager_salary_survey_2021.tsv', sep='\\t')\n",
    "df_salary.head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Was that hard? 🙃 <br>\n",
    "<b> Answer: No, but I definitely learned what a TSV file was and how powerful pandas is as all I needed to do was add the 'sep' argument </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### rename the file to something that is better for all systems.  \n",
    "* No spaces in filename (can use '_')\n",
    "* all lower case <br>\n",
    "\n",
    "<b> new file name: manager_salary_survey_2021.tsv </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore\n",
    "\n",
    "You know the drill."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How much data did you just load? <br>\n",
    "<b> 28062 Rows and 18 Columns/Features </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28062, 18)"
      ]
     },
     "execution_count": 461,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count by hand. I’m dead serious.\n",
    "df_salary.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are the columns and their types?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestamp                                                                                                                                                                                                                                object\n",
      "How old are you?                                                                                                                                                                                                                         object\n",
      "What industry do you work in?                                                                                                                                                                                                            object\n",
      "Job title                                                                                                                                                                                                                                object\n",
      "If your job title needs additional context, please clarify here:                                                                                                                                                                         object\n",
      "What is your annual salary? (You'll indicate the currency in a later question. If you are part-time or hourly, please enter an annualized equivalent -- what you would earn if you worked the job 40 hours a week, 52 weeks a year.)     object\n",
      "How much additional monetary compensation do you get, if any (for example, bonuses or overtime in an average year)? Please only include monetary compensation here, not the value of benefits.                                          float64\n",
      "Please indicate the currency                                                                                                                                                                                                             object\n",
      "If \"Other,\" please indicate the currency here:                                                                                                                                                                                           object\n",
      "If your income needs additional context, please provide it here:                                                                                                                                                                         object\n",
      "What country do you work in?                                                                                                                                                                                                             object\n",
      "If you're in the U.S., what state do you work in?                                                                                                                                                                                        object\n",
      "What city do you work in?                                                                                                                                                                                                                object\n",
      "How many years of professional work experience do you have overall?                                                                                                                                                                      object\n",
      "How many years of professional work experience do you have in your field?                                                                                                                                                                object\n",
      "What is your highest level of education completed?                                                                                                                                                                                       object\n",
      "What is your gender?                                                                                                                                                                                                                     object\n",
      "What is your race? (Choose all that apply.)                                                                                                                                                                                              object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Show the column names and their types.\n",
    "print(df_salary.dtypes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oh… Ugh! Give these columns easier names to work with first. 🙄"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename ‘em.\n",
    "\n",
    "# Colnames array\n",
    "colnames = [\n",
    "    'timestamp', 'age', 'industry', 'title', 'title_context', 'salary', \n",
    "    'additional_compensation', 'currency', 'other_currency', 'salary_context', \n",
    "    'country', 'state', 'city', 'total_yoe', 'field_yoe', 'highest_education_completed',\n",
    "    'gender', 'race'\n",
    "]\n",
    "\n",
    "# Change colnames to use colnames array\n",
    "df_salary.columns = colnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timestamp                       object\n",
      "age                             object\n",
      "industry                        object\n",
      "title                           object\n",
      "title_context                   object\n",
      "salary                          object\n",
      "additional_compensation        float64\n",
      "currency                        object\n",
      "other_currency                  object\n",
      "salary_context                  object\n",
      "country                         object\n",
      "state                           object\n",
      "city                            object\n",
      "total_yoe                       object\n",
      "field_yoe                       object\n",
      "highest_education_completed     object\n",
      "gender                          object\n",
      "race                            object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df_salary.dtypes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It’s a lot, and that should not have been easy. 😏"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You’re going to have a gander at the computing/tech subset first because thats *your* industry. But first, what value corresponds to that `industry`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Education (Higher Education)', 'Computing or Tech',\n",
       "       'Accounting, Banking & Finance', ...,\n",
       "       \"I'm currently a student and don't have a job\", 'Student ',\n",
       "       'Wine & Spirits'], dtype=object)"
      ]
     },
     "execution_count": 465,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List the unique industries and a count of their instances.\n",
    "df_salary['industry'].unique()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That value among the top 5 is what you’re looking for innit? Filter out all the rows not in that industry and save it into a new dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtery filter. (Save it to a new variable, df_salary_tech.)\n",
    "df_salary_tech = df_salary[df_salary['industry'] == 'Computing or Tech']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do a sanity check to make sure that the only values you kept are the one you are filtered for.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>age</th>\n",
       "      <th>industry</th>\n",
       "      <th>title</th>\n",
       "      <th>title_context</th>\n",
       "      <th>salary</th>\n",
       "      <th>additional_compensation</th>\n",
       "      <th>currency</th>\n",
       "      <th>other_currency</th>\n",
       "      <th>salary_context</th>\n",
       "      <th>country</th>\n",
       "      <th>state</th>\n",
       "      <th>city</th>\n",
       "      <th>total_yoe</th>\n",
       "      <th>field_yoe</th>\n",
       "      <th>highest_education_completed</th>\n",
       "      <th>gender</th>\n",
       "      <th>race</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4/27/2021 11:02:22</td>\n",
       "      <td>25-34</td>\n",
       "      <td>Computing or Tech</td>\n",
       "      <td>Change &amp; Internal Communications Manager</td>\n",
       "      <td>NaN</td>\n",
       "      <td>54,600</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>GBP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cambridge</td>\n",
       "      <td>8 - 10 years</td>\n",
       "      <td>5-7 years</td>\n",
       "      <td>College degree</td>\n",
       "      <td>Non-binary</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4/27/2021 11:03:01</td>\n",
       "      <td>45-54</td>\n",
       "      <td>Computing or Tech</td>\n",
       "      <td>Systems Analyst</td>\n",
       "      <td>Data developer/ETL Developer</td>\n",
       "      <td>112,000</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>Missouri</td>\n",
       "      <td>St. Louis</td>\n",
       "      <td>21 - 30 years</td>\n",
       "      <td>21 - 30 years</td>\n",
       "      <td>College degree</td>\n",
       "      <td>Woman</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>4/27/2021 11:04:04</td>\n",
       "      <td>25-34</td>\n",
       "      <td>Computing or Tech</td>\n",
       "      <td>Principal Software Engineer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>187,500</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United States</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>Pittsburgh</td>\n",
       "      <td>8 - 10 years</td>\n",
       "      <td>5-7 years</td>\n",
       "      <td>College degree</td>\n",
       "      <td>Woman</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>4/27/2021 11:04:04</td>\n",
       "      <td>25-34</td>\n",
       "      <td>Computing or Tech</td>\n",
       "      <td>Intelligence Analyst</td>\n",
       "      <td>NaN</td>\n",
       "      <td>110,000</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Around 20,000 a year in stock</td>\n",
       "      <td>USA</td>\n",
       "      <td>Virginia</td>\n",
       "      <td>Arlington, VA</td>\n",
       "      <td>8 - 10 years</td>\n",
       "      <td>8 - 10 years</td>\n",
       "      <td>Master's degree</td>\n",
       "      <td>Man</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>4/27/2021 11:04:07</td>\n",
       "      <td>35-44</td>\n",
       "      <td>Computing or Tech</td>\n",
       "      <td>Mobile developer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>144,600</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>USA</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>Boston</td>\n",
       "      <td>5-7 years</td>\n",
       "      <td>5-7 years</td>\n",
       "      <td>PhD</td>\n",
       "      <td>Woman</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28050</th>\n",
       "      <td>7/1/2024 13:38:46</td>\n",
       "      <td>25-34</td>\n",
       "      <td>Computing or Tech</td>\n",
       "      <td>Research &amp; Systems Technician Data Analytics</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EUR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Spain</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Barcelona</td>\n",
       "      <td>2 - 4 years</td>\n",
       "      <td>2 - 4 years</td>\n",
       "      <td>College degree</td>\n",
       "      <td>Man</td>\n",
       "      <td>Hispanic, Latino, or Spanish origin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28051</th>\n",
       "      <td>7/1/2024 20:05:58</td>\n",
       "      <td>25-34</td>\n",
       "      <td>Computing or Tech</td>\n",
       "      <td>Junior data analyst</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35000</td>\n",
       "      <td>15000.0</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Usa</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>2 - 4 years</td>\n",
       "      <td>2 - 4 years</td>\n",
       "      <td>College degree</td>\n",
       "      <td>Woman</td>\n",
       "      <td>Black or African American</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28052</th>\n",
       "      <td>7/3/2024 14:02:01</td>\n",
       "      <td>25-34</td>\n",
       "      <td>Computing or Tech</td>\n",
       "      <td>Senior Global Public Relations Manager</td>\n",
       "      <td>NaN</td>\n",
       "      <td>144000</td>\n",
       "      <td>15000.0</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Usa</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>Boise-but remote. Company located in Boston</td>\n",
       "      <td>8 - 10 years</td>\n",
       "      <td>8 - 10 years</td>\n",
       "      <td>Master's degree</td>\n",
       "      <td>Woman</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28058</th>\n",
       "      <td>7/23/2024 17:51:03</td>\n",
       "      <td>25-34</td>\n",
       "      <td>Computing or Tech</td>\n",
       "      <td>Systems Architect</td>\n",
       "      <td>NaN</td>\n",
       "      <td>109000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>USA</td>\n",
       "      <td>Georgia</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>5-7 years</td>\n",
       "      <td>5-7 years</td>\n",
       "      <td>College degree</td>\n",
       "      <td>Man</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28060</th>\n",
       "      <td>7/26/2024 11:20:45</td>\n",
       "      <td>18-24</td>\n",
       "      <td>Computing or Tech</td>\n",
       "      <td>IT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1700</td>\n",
       "      <td>10.0</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Burma</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yangon</td>\n",
       "      <td>2 - 4 years</td>\n",
       "      <td>1 year or less</td>\n",
       "      <td>Some college</td>\n",
       "      <td>Man</td>\n",
       "      <td>Asian or Asian American</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4699 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                timestamp    age           industry  \\\n",
       "1      4/27/2021 11:02:22  25-34  Computing or Tech   \n",
       "8      4/27/2021 11:03:01  45-54  Computing or Tech   \n",
       "43     4/27/2021 11:04:04  25-34  Computing or Tech   \n",
       "44     4/27/2021 11:04:04  25-34  Computing or Tech   \n",
       "46     4/27/2021 11:04:07  35-44  Computing or Tech   \n",
       "...                   ...    ...                ...   \n",
       "28050   7/1/2024 13:38:46  25-34  Computing or Tech   \n",
       "28051   7/1/2024 20:05:58  25-34  Computing or Tech   \n",
       "28052   7/3/2024 14:02:01  25-34  Computing or Tech   \n",
       "28058  7/23/2024 17:51:03  25-34  Computing or Tech   \n",
       "28060  7/26/2024 11:20:45  18-24  Computing or Tech   \n",
       "\n",
       "                                              title  \\\n",
       "1          Change & Internal Communications Manager   \n",
       "8                                   Systems Analyst   \n",
       "43                      Principal Software Engineer   \n",
       "44                             Intelligence Analyst   \n",
       "46                                 Mobile developer   \n",
       "...                                             ...   \n",
       "28050  Research & Systems Technician Data Analytics   \n",
       "28051                          Junior data analyst    \n",
       "28052        Senior Global Public Relations Manager   \n",
       "28058                             Systems Architect   \n",
       "28060                                            IT   \n",
       "\n",
       "                      title_context   salary  additional_compensation  \\\n",
       "1                               NaN   54,600                   4000.0   \n",
       "8      Data developer/ETL Developer  112,000                  10000.0   \n",
       "43                              NaN  187,500                   5000.0   \n",
       "44                              NaN  110,000                  20000.0   \n",
       "46                              NaN  144,600                   2500.0   \n",
       "...                             ...      ...                      ...   \n",
       "28050                           NaN    22000                      NaN   \n",
       "28051                           NaN    35000                  15000.0   \n",
       "28052                           NaN   144000                  15000.0   \n",
       "28058                           NaN   109000                      NaN   \n",
       "28060                           NaN     1700                     10.0   \n",
       "\n",
       "      currency other_currency                 salary_context         country  \\\n",
       "1          GBP            NaN                            NaN  United Kingdom   \n",
       "8          USD            NaN                            NaN              US   \n",
       "43         USD            NaN                            NaN   United States   \n",
       "44         USD            NaN  Around 20,000 a year in stock             USA   \n",
       "46         USD            NaN                            NaN             USA   \n",
       "...        ...            ...                            ...             ...   \n",
       "28050      EUR            NaN                            NaN           Spain   \n",
       "28051      USD            NaN                            NaN             Usa   \n",
       "28052      USD            NaN                            NaN             Usa   \n",
       "28058      USD            NaN                            NaN             USA   \n",
       "28060      USD            NaN                            NaN           Burma   \n",
       "\n",
       "               state                                          city  \\\n",
       "1                NaN                                     Cambridge   \n",
       "8           Missouri                                     St. Louis   \n",
       "43      Pennsylvania                                    Pittsburgh   \n",
       "44          Virginia                                 Arlington, VA   \n",
       "46     Massachusetts                                        Boston   \n",
       "...              ...                                           ...   \n",
       "28050            NaN                                     Barcelona   \n",
       "28051        Alabama                                      Alabama    \n",
       "28052  Massachusetts  Boise-but remote. Company located in Boston    \n",
       "28058        Georgia                                       Atlanta   \n",
       "28060            NaN                                        Yangon   \n",
       "\n",
       "           total_yoe       field_yoe highest_education_completed      gender  \\\n",
       "1       8 - 10 years       5-7 years              College degree  Non-binary   \n",
       "8      21 - 30 years   21 - 30 years              College degree       Woman   \n",
       "43      8 - 10 years       5-7 years              College degree       Woman   \n",
       "44      8 - 10 years    8 - 10 years             Master's degree         Man   \n",
       "46         5-7 years       5-7 years                         PhD       Woman   \n",
       "...              ...             ...                         ...         ...   \n",
       "28050    2 - 4 years     2 - 4 years              College degree         Man   \n",
       "28051    2 - 4 years     2 - 4 years              College degree       Woman   \n",
       "28052   8 - 10 years    8 - 10 years             Master's degree       Woman   \n",
       "28058      5-7 years       5-7 years              College degree         Man   \n",
       "28060    2 - 4 years  1 year or less                Some college         Man   \n",
       "\n",
       "                                      race  \n",
       "1                                    White  \n",
       "8                                    White  \n",
       "43                                   White  \n",
       "44                                   White  \n",
       "46                                   White  \n",
       "...                                    ...  \n",
       "28050  Hispanic, Latino, or Spanish origin  \n",
       "28051            Black or African American  \n",
       "28052                                White  \n",
       "28058                                White  \n",
       "28060              Asian or Asian American  \n",
       "\n",
       "[4699 rows x 18 columns]"
      ]
     },
     "execution_count": 467,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sanity Check \n",
    "df_salary_tech\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are very interested in salary figures. But how many dollars 💵 is a euro 💶 or a pound 💷? That sounds like a problem for another day. 🫠\n",
    "\n",
    "For now, let’s just look at U.S. dollars (`'USD'`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>age</th>\n",
       "      <th>industry</th>\n",
       "      <th>title</th>\n",
       "      <th>title_context</th>\n",
       "      <th>salary</th>\n",
       "      <th>additional_compensation</th>\n",
       "      <th>currency</th>\n",
       "      <th>other_currency</th>\n",
       "      <th>salary_context</th>\n",
       "      <th>country</th>\n",
       "      <th>state</th>\n",
       "      <th>city</th>\n",
       "      <th>total_yoe</th>\n",
       "      <th>field_yoe</th>\n",
       "      <th>highest_education_completed</th>\n",
       "      <th>gender</th>\n",
       "      <th>race</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4/27/2021 11:03:01</td>\n",
       "      <td>45-54</td>\n",
       "      <td>Computing or Tech</td>\n",
       "      <td>Systems Analyst</td>\n",
       "      <td>Data developer/ETL Developer</td>\n",
       "      <td>112,000</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>Missouri</td>\n",
       "      <td>St. Louis</td>\n",
       "      <td>21 - 30 years</td>\n",
       "      <td>21 - 30 years</td>\n",
       "      <td>College degree</td>\n",
       "      <td>Woman</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>4/27/2021 11:04:04</td>\n",
       "      <td>25-34</td>\n",
       "      <td>Computing or Tech</td>\n",
       "      <td>Principal Software Engineer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>187,500</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United States</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>Pittsburgh</td>\n",
       "      <td>8 - 10 years</td>\n",
       "      <td>5-7 years</td>\n",
       "      <td>College degree</td>\n",
       "      <td>Woman</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>4/27/2021 11:04:04</td>\n",
       "      <td>25-34</td>\n",
       "      <td>Computing or Tech</td>\n",
       "      <td>Intelligence Analyst</td>\n",
       "      <td>NaN</td>\n",
       "      <td>110,000</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Around 20,000 a year in stock</td>\n",
       "      <td>USA</td>\n",
       "      <td>Virginia</td>\n",
       "      <td>Arlington, VA</td>\n",
       "      <td>8 - 10 years</td>\n",
       "      <td>8 - 10 years</td>\n",
       "      <td>Master's degree</td>\n",
       "      <td>Man</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>4/27/2021 11:04:07</td>\n",
       "      <td>35-44</td>\n",
       "      <td>Computing or Tech</td>\n",
       "      <td>Mobile developer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>144,600</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>USA</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>Boston</td>\n",
       "      <td>5-7 years</td>\n",
       "      <td>5-7 years</td>\n",
       "      <td>PhD</td>\n",
       "      <td>Woman</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>4/27/2021 11:04:09</td>\n",
       "      <td>35-44</td>\n",
       "      <td>Computing or Tech</td>\n",
       "      <td>Product Design Director</td>\n",
       "      <td>NaN</td>\n",
       "      <td>200,850</td>\n",
       "      <td>40000.0</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>USA</td>\n",
       "      <td>North Carolina</td>\n",
       "      <td>Chapel Hill</td>\n",
       "      <td>11 - 20 years</td>\n",
       "      <td>11 - 20 years</td>\n",
       "      <td>College degree</td>\n",
       "      <td>Woman</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28044</th>\n",
       "      <td>6/3/2024 16:15:43</td>\n",
       "      <td>18-24</td>\n",
       "      <td>Computing or Tech</td>\n",
       "      <td>Research Data Analyst Associate</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United States</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>Evanston</td>\n",
       "      <td>2 - 4 years</td>\n",
       "      <td>1 year or less</td>\n",
       "      <td>College degree</td>\n",
       "      <td>Woman</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28051</th>\n",
       "      <td>7/1/2024 20:05:58</td>\n",
       "      <td>25-34</td>\n",
       "      <td>Computing or Tech</td>\n",
       "      <td>Junior data analyst</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35000</td>\n",
       "      <td>15000.0</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Usa</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>2 - 4 years</td>\n",
       "      <td>2 - 4 years</td>\n",
       "      <td>College degree</td>\n",
       "      <td>Woman</td>\n",
       "      <td>Black or African American</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28052</th>\n",
       "      <td>7/3/2024 14:02:01</td>\n",
       "      <td>25-34</td>\n",
       "      <td>Computing or Tech</td>\n",
       "      <td>Senior Global Public Relations Manager</td>\n",
       "      <td>NaN</td>\n",
       "      <td>144000</td>\n",
       "      <td>15000.0</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Usa</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>Boise-but remote. Company located in Boston</td>\n",
       "      <td>8 - 10 years</td>\n",
       "      <td>8 - 10 years</td>\n",
       "      <td>Master's degree</td>\n",
       "      <td>Woman</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28058</th>\n",
       "      <td>7/23/2024 17:51:03</td>\n",
       "      <td>25-34</td>\n",
       "      <td>Computing or Tech</td>\n",
       "      <td>Systems Architect</td>\n",
       "      <td>NaN</td>\n",
       "      <td>109000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>USA</td>\n",
       "      <td>Georgia</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>5-7 years</td>\n",
       "      <td>5-7 years</td>\n",
       "      <td>College degree</td>\n",
       "      <td>Man</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28060</th>\n",
       "      <td>7/26/2024 11:20:45</td>\n",
       "      <td>18-24</td>\n",
       "      <td>Computing or Tech</td>\n",
       "      <td>IT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1700</td>\n",
       "      <td>10.0</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Burma</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yangon</td>\n",
       "      <td>2 - 4 years</td>\n",
       "      <td>1 year or less</td>\n",
       "      <td>Some college</td>\n",
       "      <td>Man</td>\n",
       "      <td>Asian or Asian American</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3777 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                timestamp    age           industry  \\\n",
       "8      4/27/2021 11:03:01  45-54  Computing or Tech   \n",
       "43     4/27/2021 11:04:04  25-34  Computing or Tech   \n",
       "44     4/27/2021 11:04:04  25-34  Computing or Tech   \n",
       "46     4/27/2021 11:04:07  35-44  Computing or Tech   \n",
       "47     4/27/2021 11:04:09  35-44  Computing or Tech   \n",
       "...                   ...    ...                ...   \n",
       "28044   6/3/2024 16:15:43  18-24  Computing or Tech   \n",
       "28051   7/1/2024 20:05:58  25-34  Computing or Tech   \n",
       "28052   7/3/2024 14:02:01  25-34  Computing or Tech   \n",
       "28058  7/23/2024 17:51:03  25-34  Computing or Tech   \n",
       "28060  7/26/2024 11:20:45  18-24  Computing or Tech   \n",
       "\n",
       "                                        title                 title_context  \\\n",
       "8                             Systems Analyst  Data developer/ETL Developer   \n",
       "43                Principal Software Engineer                           NaN   \n",
       "44                       Intelligence Analyst                           NaN   \n",
       "46                           Mobile developer                           NaN   \n",
       "47                    Product Design Director                           NaN   \n",
       "...                                       ...                           ...   \n",
       "28044         Research Data Analyst Associate                           NaN   \n",
       "28051                    Junior data analyst                            NaN   \n",
       "28052  Senior Global Public Relations Manager                           NaN   \n",
       "28058                       Systems Architect                           NaN   \n",
       "28060                                      IT                           NaN   \n",
       "\n",
       "        salary  additional_compensation currency other_currency  \\\n",
       "8      112,000                  10000.0      USD            NaN   \n",
       "43     187,500                   5000.0      USD            NaN   \n",
       "44     110,000                  20000.0      USD            NaN   \n",
       "46     144,600                   2500.0      USD            NaN   \n",
       "47     200,850                  40000.0      USD            NaN   \n",
       "...        ...                      ...      ...            ...   \n",
       "28044    60000                      0.0      USD            NaN   \n",
       "28051    35000                  15000.0      USD            NaN   \n",
       "28052   144000                  15000.0      USD            NaN   \n",
       "28058   109000                      NaN      USD            NaN   \n",
       "28060     1700                     10.0      USD            NaN   \n",
       "\n",
       "                      salary_context        country           state  \\\n",
       "8                                NaN             US        Missouri   \n",
       "43                               NaN  United States    Pennsylvania   \n",
       "44     Around 20,000 a year in stock            USA        Virginia   \n",
       "46                               NaN            USA   Massachusetts   \n",
       "47                               NaN            USA  North Carolina   \n",
       "...                              ...            ...             ...   \n",
       "28044                            NaN  United States        Illinois   \n",
       "28051                            NaN            Usa         Alabama   \n",
       "28052                            NaN            Usa   Massachusetts   \n",
       "28058                            NaN            USA         Georgia   \n",
       "28060                            NaN          Burma             NaN   \n",
       "\n",
       "                                               city      total_yoe  \\\n",
       "8                                         St. Louis  21 - 30 years   \n",
       "43                                       Pittsburgh   8 - 10 years   \n",
       "44                                    Arlington, VA   8 - 10 years   \n",
       "46                                           Boston      5-7 years   \n",
       "47                                      Chapel Hill  11 - 20 years   \n",
       "...                                             ...            ...   \n",
       "28044                                      Evanston    2 - 4 years   \n",
       "28051                                      Alabama     2 - 4 years   \n",
       "28052  Boise-but remote. Company located in Boston    8 - 10 years   \n",
       "28058                                       Atlanta      5-7 years   \n",
       "28060                                        Yangon    2 - 4 years   \n",
       "\n",
       "            field_yoe highest_education_completed gender  \\\n",
       "8       21 - 30 years              College degree  Woman   \n",
       "43          5-7 years              College degree  Woman   \n",
       "44       8 - 10 years             Master's degree    Man   \n",
       "46          5-7 years                         PhD  Woman   \n",
       "47      11 - 20 years              College degree  Woman   \n",
       "...               ...                         ...    ...   \n",
       "28044  1 year or less              College degree  Woman   \n",
       "28051     2 - 4 years              College degree  Woman   \n",
       "28052    8 - 10 years             Master's degree  Woman   \n",
       "28058       5-7 years              College degree    Man   \n",
       "28060  1 year or less                Some college    Man   \n",
       "\n",
       "                            race  \n",
       "8                          White  \n",
       "43                         White  \n",
       "44                         White  \n",
       "46                         White  \n",
       "47                         White  \n",
       "...                          ...  \n",
       "28044                      White  \n",
       "28051  Black or African American  \n",
       "28052                      White  \n",
       "28058                      White  \n",
       "28060    Asian or Asian American  \n",
       "\n",
       "[3777 rows x 18 columns]"
      ]
     },
     "execution_count": 468,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filtery filter for just the jobs that pay in USD!\n",
    "df_salary_tech = df_salary_tech[df_salary_tech['currency'] == 'USD']\n",
    "df_salary_tech"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we really want know is how each U.S. city pays in tech. What value in `country` represents the United States of America?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['US', 'United States', 'USA', 'United States of America',\n",
       "       'United States ', 'U.S. ', 'US ', 'usa', 'United states',\n",
       "       'United State of America', 'USA ', 'U.S.', 'us', 'Usa',\n",
       "       'united states', 'Uniyed states', 'U.S.A.', 'America',\n",
       "       'Puerto Rico ', 'U.s.', ' US', 'Unite States', 'Us',\n",
       "       'United State', 'Australia', 'Cuba', 'Danmark', 'Canada', 'Italy',\n",
       "       'International ', 'UnitedStates', 'Israel', 'India',\n",
       "       'United Stated', 'U.S', 'Usa ', 'Remote (philippines)',\n",
       "       'Singapore', 'United States Of America', 'Spain',\n",
       "       'United States of America ', 'Uruguay', 'Brazil', 'Mexico',\n",
       "       'United Kingdom', 'Canada ', 'United Stateds', 'ISA', 'singapore',\n",
       "       'Pakistan', 'united States', 'New Zealand', 'Poland', 'France',\n",
       "       'Netherlands', 'China', 'San Francisco', 'Romania',\n",
       "       'United STates', 'Japan', 'U.S.A', 'United Stares',\n",
       "       'United States of america', 'Australian ', 'Denmark', 'Jamaica',\n",
       "       'Unites States', 'Thailand', 'U.S.A ', 'Colombia', 'denmark',\n",
       "       'Ghana', 'Nigeria ', 'ss', 'Nigeria', 'Burma'], dtype=object)"
      ]
     },
     "execution_count": 469,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We did filter for USD, so if we do a count of each unique country in descending count order, the relevant value(s) should show up at the top.\n",
    "df_salary_tech['country'].unique()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean the Data\n",
    "\n",
    "Well, we can’t get our answers with what we currently have, so you’ll have to make some changes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s not worry about anything below the first 5 values for now. Convert the top 5 to a single canonical value―say, `'US'`, which is nice and short."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usflo\\AppData\\Local\\Temp\\ipykernel_2108\\4112592190.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_salary_tech['country'] = df_salary_tech['country'].replace(us_entries, 'US')\n"
     ]
    }
   ],
   "source": [
    "# Replace them all with 'US'.\n",
    "us_entries = ['US', 'United States', 'USA', 'United States of America', 'United States ', 'U.S. ', \n",
    " 'US ', 'usa', 'United states', 'United State of America', 'USA ', 'U.S.', 'us', 'Usa', \n",
    " 'united states', 'Uniyed states', 'U.S.A.', 'America', 'U.s.', ' US', 'Unite States', \n",
    " 'Us', 'United State', 'UnitedStates', 'United Stated', 'U.S', 'Usa ', \n",
    " 'United States Of America', 'United States of America ', 'ISA', 'united States', \n",
    " 'United STates', 'U.S.A', 'United Stares', 'United States of america', 'ss', 'United Stateds', 'Unites States', 'San Francisco', \n",
    " 'U.S.A ']\n",
    "\n",
    "df_salary_tech['country'] = df_salary_tech['country'].replace(us_entries, 'US')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Have a look at the count of each unique country again now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['US', 'Puerto Rico ', 'Australia', 'Cuba', 'Danmark', 'Canada',\n",
       "       'Italy', 'International ', 'Israel', 'India',\n",
       "       'Remote (philippines)', 'Singapore', 'Spain', 'Uruguay', 'Brazil',\n",
       "       'Mexico', 'United Kingdom', 'Canada ', 'singapore', 'Pakistan',\n",
       "       'New Zealand', 'Poland', 'France', 'Netherlands', 'China',\n",
       "       'Romania', 'Japan', 'Australian ', 'Denmark', 'Jamaica',\n",
       "       'Thailand', 'Colombia', 'denmark', 'Ghana', 'Nigeria ', 'Nigeria',\n",
       "       'Burma'], dtype=object)"
      ]
     },
     "execution_count": 471,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count again.\n",
    "df_salary_tech['country'].unique()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Did you notice anything interesting?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I took all varieties of USA into account even the not so obvious ones like: 'ss', I had to check the 'state' column to verify if it was in the USA\n"
     ]
    }
   ],
   "source": [
    "# BONUS CREDIT: resolve [most of] those anomalous cases too without exhaustively taking every variant literally into account.\n",
    "print(\"I took all varieties of USA into account even the not so obvious ones like: 'ss', I had to check the 'state' column to verify if it was in the USA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I turned all unique values into 'US' \n",
      "\n",
      " But here are other entires: \n",
      "  \n",
      "['US', 'Puerto Rico ', 'Australia', 'Cuba', 'Danmark', 'Canada',\n",
      "       'Italy', 'International ', 'Israel', 'India',\n",
      "       'Remote (philippines)', 'Singapore', 'Spain', 'Uruguay', 'Brazil',\n",
      "       'Mexico', 'United Kingdom', 'Canada ', 'singapore', 'Pakistan',\n",
      "       'New Zealand', 'Poland', 'France', 'Netherlands', 'China',\n",
      "       'Romania', 'Japan', 'Australian ', 'Denmark', 'Jamaica',\n",
      "       'Thailand', 'Colombia', 'denmark', 'Ghana', 'Nigeria ', 'Nigeria',\n",
      "       'Burma']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# BONUS CREDIT: if you’ve resolved it, let’s see how well you did by counting the number of instances of each unique value.\n",
    "unique = ''' \n",
    "['US', 'Puerto Rico ', 'Australia', 'Cuba', 'Danmark', 'Canada',\n",
    "       'Italy', 'International ', 'Israel', 'India',\n",
    "       'Remote (philippines)', 'Singapore', 'Spain', 'Uruguay', 'Brazil',\n",
    "       'Mexico', 'United Kingdom', 'Canada ', 'singapore', 'Pakistan',\n",
    "       'New Zealand', 'Poland', 'France', 'Netherlands', 'China',\n",
    "       'Romania', 'Japan', 'Australian ', 'Denmark', 'Jamaica',\n",
    "       'Thailand', 'Colombia', 'denmark', 'Ghana', 'Nigeria ', 'Nigeria',\n",
    "       'Burma']\n",
    "'''\n",
    "print(f\"I turned all unique values into 'US' \\n\\n But here are other entires: \\n {unique}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It’s looking good so far. Let’s find out the minimum, mean, and maximum (in that order) salary by state, sorted by the mean in descending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "agg function failed [how->mean,dtype->object]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\usflo\\anaconda3\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1874\u001b[0m, in \u001b[0;36mGroupBy._agg_py_fallback\u001b[1;34m(self, how, values, ndim, alt)\u001b[0m\n\u001b[0;32m   1873\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1874\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrouper\u001b[38;5;241m.\u001b[39magg_series(ser, alt, preserve_dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   1875\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\Users\\usflo\\anaconda3\\Lib\\site-packages\\pandas\\core\\groupby\\ops.py:849\u001b[0m, in \u001b[0;36mBaseGrouper.agg_series\u001b[1;34m(self, obj, func, preserve_dtype)\u001b[0m\n\u001b[0;32m    847\u001b[0m     preserve_dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 849\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_aggregate_series_pure_python(obj, func)\n\u001b[0;32m    851\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(obj) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(result) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, ExtensionDtype):\n",
      "File \u001b[1;32mc:\\Users\\usflo\\anaconda3\\Lib\\site-packages\\pandas\\core\\groupby\\ops.py:877\u001b[0m, in \u001b[0;36mBaseGrouper._aggregate_series_pure_python\u001b[1;34m(self, obj, func)\u001b[0m\n\u001b[0;32m    876\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, group \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(splitter):\n\u001b[1;32m--> 877\u001b[0m     res \u001b[38;5;241m=\u001b[39m func(group)\n\u001b[0;32m    878\u001b[0m     res \u001b[38;5;241m=\u001b[39m extract_result(res)\n",
      "File \u001b[1;32mc:\\Users\\usflo\\anaconda3\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:2380\u001b[0m, in \u001b[0;36mGroupBy.mean.<locals>.<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m   2377\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2378\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cython_agg_general(\n\u001b[0;32m   2379\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m-> 2380\u001b[0m         alt\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: Series(x)\u001b[38;5;241m.\u001b[39mmean(numeric_only\u001b[38;5;241m=\u001b[39mnumeric_only),\n\u001b[0;32m   2381\u001b[0m         numeric_only\u001b[38;5;241m=\u001b[39mnumeric_only,\n\u001b[0;32m   2382\u001b[0m     )\n\u001b[0;32m   2383\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgroupby\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\usflo\\anaconda3\\Lib\\site-packages\\pandas\\core\\series.py:6225\u001b[0m, in \u001b[0;36mSeries.mean\u001b[1;34m(self, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[0;32m   6217\u001b[0m \u001b[38;5;129m@doc\u001b[39m(make_doc(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m, ndim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m   6218\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmean\u001b[39m(\n\u001b[0;32m   6219\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   6223\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   6224\u001b[0m ):\n\u001b[1;32m-> 6225\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m NDFrame\u001b[38;5;241m.\u001b[39mmean(\u001b[38;5;28mself\u001b[39m, axis, skipna, numeric_only, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\usflo\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:11992\u001b[0m, in \u001b[0;36mNDFrame.mean\u001b[1;34m(self, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[0;32m  11985\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmean\u001b[39m(\n\u001b[0;32m  11986\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m  11987\u001b[0m     axis: Axis \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  11990\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m  11991\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Series \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mfloat\u001b[39m:\n\u001b[1;32m> 11992\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stat_function(\n\u001b[0;32m  11993\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m, nanops\u001b[38;5;241m.\u001b[39mnanmean, axis, skipna, numeric_only, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m  11994\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\usflo\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:11949\u001b[0m, in \u001b[0;36mNDFrame._stat_function\u001b[1;34m(self, name, func, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[0;32m  11947\u001b[0m validate_bool_kwarg(skipna, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskipna\u001b[39m\u001b[38;5;124m\"\u001b[39m, none_allowed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m> 11949\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reduce(\n\u001b[0;32m  11950\u001b[0m     func, name\u001b[38;5;241m=\u001b[39mname, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, numeric_only\u001b[38;5;241m=\u001b[39mnumeric_only\n\u001b[0;32m  11951\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\usflo\\anaconda3\\Lib\\site-packages\\pandas\\core\\series.py:6133\u001b[0m, in \u001b[0;36mSeries._reduce\u001b[1;34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001b[0m\n\u001b[0;32m   6129\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m   6130\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSeries.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not allow \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkwd_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnumeric_only\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   6131\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwith non-numeric dtypes.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   6132\u001b[0m     )\n\u001b[1;32m-> 6133\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m op(delegate, skipna\u001b[38;5;241m=\u001b[39mskipna, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "File \u001b[1;32mc:\\Users\\usflo\\anaconda3\\Lib\\site-packages\\pandas\\core\\nanops.py:147\u001b[0m, in \u001b[0;36mbottleneck_switch.__call__.<locals>.f\u001b[1;34m(values, axis, skipna, **kwds)\u001b[0m\n\u001b[0;32m    146\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 147\u001b[0m     result \u001b[38;5;241m=\u001b[39m alt(values, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\usflo\\anaconda3\\Lib\\site-packages\\pandas\\core\\nanops.py:404\u001b[0m, in \u001b[0;36m_datetimelike_compat.<locals>.new_func\u001b[1;34m(values, axis, skipna, mask, **kwargs)\u001b[0m\n\u001b[0;32m    402\u001b[0m     mask \u001b[38;5;241m=\u001b[39m isna(values)\n\u001b[1;32m--> 404\u001b[0m result \u001b[38;5;241m=\u001b[39m func(values, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, mask\u001b[38;5;241m=\u001b[39mmask, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    406\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m datetimelike:\n",
      "File \u001b[1;32mc:\\Users\\usflo\\anaconda3\\Lib\\site-packages\\pandas\\core\\nanops.py:720\u001b[0m, in \u001b[0;36mnanmean\u001b[1;34m(values, axis, skipna, mask)\u001b[0m\n\u001b[0;32m    719\u001b[0m the_sum \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39msum(axis, dtype\u001b[38;5;241m=\u001b[39mdtype_sum)\n\u001b[1;32m--> 720\u001b[0m the_sum \u001b[38;5;241m=\u001b[39m _ensure_numeric(the_sum)\n\u001b[0;32m    722\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(the_sum, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mndim\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "File \u001b[1;32mc:\\Users\\usflo\\anaconda3\\Lib\\site-packages\\pandas\\core\\nanops.py:1693\u001b[0m, in \u001b[0;36m_ensure_numeric\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m   1691\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m   1692\u001b[0m     \u001b[38;5;66;03m# GH#44008, GH#36703 avoid casting e.g. strings to numeric\u001b[39;00m\n\u001b[1;32m-> 1693\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not convert string \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m to numeric\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1694\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[1;31mTypeError\u001b[0m: Could not convert string '75,00070,00072,00052,00029,120105,000120,00052000550009500035000035000' to numeric",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[474], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Find the minimum, mean, and maximum salary in USD by U.S. state.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m min_val \u001b[38;5;241m=\u001b[39m df_salary_tech\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstate\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msalary\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmin()\n\u001b[1;32m----> 3\u001b[0m mean_val \u001b[38;5;241m=\u001b[39m df_salary_tech\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstate\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msalary\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmean()\n\u001b[0;32m      4\u001b[0m max_val \u001b[38;5;241m=\u001b[39m df_salary\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstate\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msalary\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmax()\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(min_val)\n",
      "File \u001b[1;32mc:\\Users\\usflo\\anaconda3\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:2378\u001b[0m, in \u001b[0;36mGroupBy.mean\u001b[1;34m(self, numeric_only, engine, engine_kwargs)\u001b[0m\n\u001b[0;32m   2371\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_numba_agg_general(\n\u001b[0;32m   2372\u001b[0m         grouped_mean,\n\u001b[0;32m   2373\u001b[0m         executor\u001b[38;5;241m.\u001b[39mfloat_dtype_mapping,\n\u001b[0;32m   2374\u001b[0m         engine_kwargs,\n\u001b[0;32m   2375\u001b[0m         min_periods\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m   2376\u001b[0m     )\n\u001b[0;32m   2377\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2378\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cython_agg_general(\n\u001b[0;32m   2379\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   2380\u001b[0m         alt\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: Series(x)\u001b[38;5;241m.\u001b[39mmean(numeric_only\u001b[38;5;241m=\u001b[39mnumeric_only),\n\u001b[0;32m   2381\u001b[0m         numeric_only\u001b[38;5;241m=\u001b[39mnumeric_only,\n\u001b[0;32m   2382\u001b[0m     )\n\u001b[0;32m   2383\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgroupby\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\usflo\\anaconda3\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1929\u001b[0m, in \u001b[0;36mGroupBy._cython_agg_general\u001b[1;34m(self, how, alt, numeric_only, min_count, **kwargs)\u001b[0m\n\u001b[0;32m   1926\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_agg_py_fallback(how, values, ndim\u001b[38;5;241m=\u001b[39mdata\u001b[38;5;241m.\u001b[39mndim, alt\u001b[38;5;241m=\u001b[39malt)\n\u001b[0;32m   1927\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[1;32m-> 1929\u001b[0m new_mgr \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mgrouped_reduce(array_func)\n\u001b[0;32m   1930\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wrap_agged_manager(new_mgr)\n\u001b[0;32m   1931\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wrap_aggregated_output(res)\n",
      "File \u001b[1;32mc:\\Users\\usflo\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\base.py:336\u001b[0m, in \u001b[0;36mSingleDataManager.grouped_reduce\u001b[1;34m(self, func)\u001b[0m\n\u001b[0;32m    334\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgrouped_reduce\u001b[39m(\u001b[38;5;28mself\u001b[39m, func):\n\u001b[0;32m    335\u001b[0m     arr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39marray\n\u001b[1;32m--> 336\u001b[0m     res \u001b[38;5;241m=\u001b[39m func(arr)\n\u001b[0;32m    337\u001b[0m     index \u001b[38;5;241m=\u001b[39m default_index(\u001b[38;5;28mlen\u001b[39m(res))\n\u001b[0;32m    339\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mfrom_array(res, index)\n",
      "File \u001b[1;32mc:\\Users\\usflo\\anaconda3\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1926\u001b[0m, in \u001b[0;36mGroupBy._cython_agg_general.<locals>.array_func\u001b[1;34m(values)\u001b[0m\n\u001b[0;32m   1923\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1924\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[1;32m-> 1926\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_agg_py_fallback(how, values, ndim\u001b[38;5;241m=\u001b[39mdata\u001b[38;5;241m.\u001b[39mndim, alt\u001b[38;5;241m=\u001b[39malt)\n\u001b[0;32m   1927\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\usflo\\anaconda3\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1878\u001b[0m, in \u001b[0;36mGroupBy._agg_py_fallback\u001b[1;34m(self, how, values, ndim, alt)\u001b[0m\n\u001b[0;32m   1876\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124magg function failed [how->\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhow\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m,dtype->\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mser\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1877\u001b[0m     \u001b[38;5;66;03m# preserve the kind of exception that raised\u001b[39;00m\n\u001b[1;32m-> 1878\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(err)(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   1880\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ser\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m:\n\u001b[0;32m   1881\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m res_values\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mTypeError\u001b[0m: agg function failed [how->mean,dtype->object]"
     ]
    }
   ],
   "source": [
    "# Find the minimum, mean, and maximum salary in USD by U.S. state.\n",
    "min_val = df_salary_tech.groupby('state')['salary'].min()\n",
    "mean_val = df_salary_tech.groupby('state')['salary'].mean()\n",
    "max_val = df_salary.groupby('state')['salary'].max()\n",
    "\n",
    "print(min_val)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, pooh! We forgot that `salary` isn’t numeric. Something wrong must be fixed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix it.\n",
    "df_salary_tech['salary'] = df_salary_tech['salary'].str.replace(',', '')\n",
    "df_salary_tech['salary'] = df_salary_tech['salary'].astype(int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s try that again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That did the trick! Now let’s narrow this to data 2021 and 2022 just because (lel). *(Hint: that timestamp column may not be a temporal type right now.)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the data to within 2021, 2022, or 2023, saving the DataFrame to a new variable, and generate the summary again.\n",
    "# Find the minimum, mean, and maximum salary in USD by U.S. state.\n",
    "min_val = df_salary_tech.groupby('state')['salary'].min()\n",
    "mean_val = df_salary_tech.groupby('state')['salary'].mean()\n",
    "max_val = df_salary.groupby('state')['salary'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(min_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mean_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(max_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus\n",
    "\n",
    "Clearly, we do not have enough data to produce useful figures for the level of specificity you’ve now reached. What do you notice about Delaware and West Virginia?\n",
    "\n",
    "Let’s back out a bit and return to `df_salary` (which was the loaded data with renamed columns but *sans* filtering)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus #0\n",
    "\n",
    "Apply the same steps as before to `df_salary`, but do not filter for any specific industry. Do perform the other data cleaning stuff, and get to a point where you can generate the minimum, mean, and maximum by state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix colnames\n",
    "df_salary.columns = colnames\n",
    "# Standardize US Entries\n",
    "df_salary['country'] = df_salary['country'].replace(us_entries, 'US')\n",
    "# Convert salary to int64, int is too small \n",
    "df_salary['salary'] = df_salary['salary'].str.replace(',', '')\n",
    "df_salary['salary'] = df_salary['salary'].astype('Int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_salary_min_val = df_salary.groupby('state')['salary'].min()\n",
    "df_salary_mean_val = df_salary.groupby('state')['salary'].mean()\n",
    "df_salary_max_val = df_salary.groupby('state')['salary'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state\n",
      "Alabama                               0\n",
      "Alabama, Alaska, Arizona             15\n",
      "Alabama, California               29120\n",
      "Alabama, District of Columbia    156000\n",
      "Alabama, Kansas                   64197\n",
      "                                  ...  \n",
      "Virginia                             57\n",
      "Washington                           72\n",
      "West Virginia                         0\n",
      "Wisconsin                             1\n",
      "Wyoming                           29000\n",
      "Name: salary, Length: 134, dtype: Int64\n"
     ]
    }
   ],
   "source": [
    "print(df_salary_min_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state\n",
      "Alabama                            98178.47541\n",
      "Alabama, Alaska, Arizona                  15.0\n",
      "Alabama, California                    29120.0\n",
      "Alabama, District of Columbia         156000.0\n",
      "Alabama, Kansas                        64197.0\n",
      "                                     ...      \n",
      "Virginia                          94679.388041\n",
      "Washington                       107803.852196\n",
      "West Virginia                     59162.928571\n",
      "Wisconsin                         76351.454158\n",
      "Wyoming                           58089.291667\n",
      "Name: salary, Length: 134, dtype: Float64\n"
     ]
    }
   ],
   "source": [
    "print(df_salary_mean_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state\n",
      "Alabama                          3600000\n",
      "Alabama, Alaska, Arizona              15\n",
      "Alabama, California                29120\n",
      "Alabama, District of Columbia     156000\n",
      "Alabama, Kansas                    64197\n",
      "                                  ...   \n",
      "Virginia                         1300000\n",
      "Washington                       1260000\n",
      "West Virginia                     125000\n",
      "Wisconsin                         920000\n",
      "Wyoming                           140000\n",
      "Name: salary, Length: 134, dtype: Int64\n"
     ]
    }
   ],
   "source": [
    "print(df_salary_max_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus #1\n",
    "\n",
    "This time, format the table output nicely (*$12,345.00*) without modifying the values in the `DataFrame`. That is, `df_salary` should be identical before versus after running your code.\n",
    "\n",
    "(*Hint: if you run into an error about `jinja2` perhaps you need to `pip install` something.*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Styled object prints the entire df. It also loses the .head() method cause it became a different object\n"
     ]
    }
   ],
   "source": [
    "df_salary_styled = df_salary.style.format({'salary': '${:,.2f}'})\n",
    "# df_salary_styled\n",
    "print(\"Styled object prints the entire df. It also loses the .head() method cause it became a different object\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus #2\n",
    "\n",
    "Filter out the non-single-states (e.g., `'California, Colorado'`) in the most elegant way possible (i.e., *not* by blacklisting all the bad values)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Massachusetts', nan, 'Tennessee', 'Wisconsin', 'South Carolina',\n",
       "       'New Hampshire', 'Arizona', 'Missouri', 'Florida', 'Pennsylvania',\n",
       "       'Michigan', 'Minnesota', 'Illinois', 'California', 'Georgia',\n",
       "       'Ohio', 'District of Columbia', 'Maryland', 'Texas', 'Virginia',\n",
       "       'North Carolina', 'New York', 'New Jersey', 'Rhode Island',\n",
       "       'Colorado', 'Oregon', 'Washington', 'Indiana', 'Iowa', 'Nebraska',\n",
       "       'Oklahoma', 'Maine', 'Connecticut', 'South Dakota',\n",
       "       'West Virginia', 'Idaho', 'Louisiana', 'Montana', 'Kentucky',\n",
       "       'North Dakota', 'Kansas', 'Vermont', 'Arkansas', 'Alabama',\n",
       "       'Nevada', 'Delaware', 'New Mexico', 'Hawaii', 'Utah',\n",
       "       'Mississippi', 'Alaska', 'Wyoming'], dtype=object)"
      ]
     },
     "execution_count": 492,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List of multi-state entries\n",
    "multi_state_entries = [\n",
    "    'Kentucky, Ohio', 'District of Columbia, Virginia', 'District of Columbia, Maryland', 'Arizona, Washington',\n",
    "    'Georgia, New York', 'California, Colorado', 'California, Oregon', 'District of Columbia, Maryland, Pennsylvania, Virginia',\n",
    "    'Arizona, California', 'North Carolina, Utah', 'Ohio, Wyoming', 'Georgia, Tennessee', 'Massachusetts, Oregon', 'Alabama, Montana',\n",
    "    'Alabama, District of Columbia', 'California, Pennsylvania', 'New Jersey, Pennsylvania', 'Georgia, Washington', 'Alaska, Maryland',\n",
    "    'Michigan, South Carolina', 'Massachusetts, Rhode Island', 'Georgia, Minnesota', 'Colorado, Nevada', 'Maine, Massachusetts, New Hampshire, North Carolina',\n",
    "    'Alabama, Minnesota, Nevada', 'New Jersey, New York', 'Arizona, Utah', 'Alabama, Kansas', 'California, Oklahoma', 'Illinois, Wisconsin', 'Illinois, Kentucky',\n",
    "    'Arizona, California, Nevada, Texas', 'Alaska, Idaho, Oregon, Utah, Washington', 'Massachusetts, Pennsylvania', 'Nevada, Oregon', 'New Jersey, Virginia',\n",
    "    'Montana, Wyoming', 'Colorado, Massachusetts', 'District of Columbia, Maryland, Virginia', 'Massachusetts, Vermont', 'Massachusetts, New Hampshire',\n",
    "    'Arkansas, Iowa, Massachusetts, Ohio, Wyoming', 'New York, Texas', 'California, Montana', 'Iowa, Utah, Vermont', 'Texas, Virginia', 'Utah, Vermont',\n",
    "    'Arkansas, Illinois', 'Georgia, Massachusetts', 'Maryland, Virginia', 'Florida, Georgia, South Carolina',\n",
    "    'Arkansas, Idaho, Kansas, Louisiana, Michigan, Mississippi, Nevada, New York, South Carolina, Tennessee, Washington',\n",
    "    'California, Texas', 'Indiana, Ohio', 'Ohio, Washington', 'Kansas, Missouri', 'Colorado, Illinois',\n",
    "    'Arizona, Hawaii, Illinois, Michigan, Utah, Wyoming', 'California, New Jersey', 'Louisiana, Washington',\n",
    "    'Maryland, New York', 'District of Columbia, Washington', 'Delaware, Pennsylvania', 'Illinois, North Carolina',\n",
    "    'Indiana, Massachusetts', 'Florida, New Hampshire, Wisconsin', 'Pennsylvania, Rhode Island', 'New York, Oregon, Vermont',\n",
    "    'Iowa, Nebraska', 'California, New York', 'Arizona, New York', 'California, District of Columbia, Illinois, Iowa, Maryland, Minnesota',\n",
    "    'Oregon, Washington', 'New York, Virginia', 'Mississippi, Missouri', 'California, Maryland', 'California, Illinois, Massachusetts, North Carolina, South Carolina, Virginia',\n",
    "    'Alabama, California', 'Michigan, Texas, Washington', 'Alabama, Oregon', 'Alabama, Alaska, Arizona', 'Alabama, South Carolina',\n",
    "    'Colorado, Delaware, New Jersey, West Virginia, Wyoming'\n",
    "]\n",
    "\n",
    "# Function to replace multi-state entries with the last state\n",
    "def replace_multi_state_entries(entry):\n",
    "    if isinstance(entry, str):                          # Ensure the entry is a string (not NaN)\n",
    "        if ',' in entry:                                # Check if the entry contains multiple states\n",
    "            return entry.split(',')[-1].strip()         # Get the last state and strip any extra spaces\n",
    "    return entry                                        # Return the entry unchanged if it's a single state or NaN\n",
    "\n",
    "# Apply the function to convert multi-state entries to the last state\n",
    "df_salary['state'].astype(str)\n",
    "df_salary['state'] = df_salary['state'].apply(replace_multi_state_entries)\n",
    "\n",
    "# Display the updated DataFrame\n",
    "df_salary['state'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus #3\n",
    "\n",
    "Show the quantiles instead of just minimum, mean, and maximum―say 0%, 5%, 25%, 50%, 75%, 95%, and 100%. Outliers may be deceiving.\n",
    "\n",
    "Sort by whatever interests you―like say the *50th* percentile.\n",
    "\n",
    "And throw in a count by state too. It would be interesting to know how many data points contribute to the figures for each state. (*Hint: your nice formatting from Bonus #1 might not work this time around.* 😜)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantiles = [0, 0.05, 0.25, 0.50, 0.75, 0.95, 1.0]                                                  # Define quantiles\n",
    "quantile_stats = df_salary.groupby('state')['salary'].quantile(quantiles).unstack()                 # Obtain quantile values\n",
    "\n",
    "# Count number of rows per group\n",
    "count_by_state = df_salary.groupby('state')['salary'].count()\n",
    "\n",
    "# Merge the count information with the quantile statistics\n",
    "summary = quantile_stats.merge(count_by_state.rename('count'), left_index=True, right_index=True)\n",
    "\n",
    "# Sort by the 50th percentile \n",
    "summary_sorted = summary.sort_values(by=0.50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.0</th>\n",
       "      <th>0.05</th>\n",
       "      <th>0.25</th>\n",
       "      <th>0.5</th>\n",
       "      <th>0.75</th>\n",
       "      <th>0.95</th>\n",
       "      <th>1.0</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>state</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>West Virginia</th>\n",
       "      <td>0.0</td>\n",
       "      <td>27050.0</td>\n",
       "      <td>41250.0</td>\n",
       "      <td>49544.0</td>\n",
       "      <td>74100.0</td>\n",
       "      <td>117465.2</td>\n",
       "      <td>125000.0</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Montana</th>\n",
       "      <td>19200.0</td>\n",
       "      <td>33631.0</td>\n",
       "      <td>37125.0</td>\n",
       "      <td>49700.0</td>\n",
       "      <td>84250.0</td>\n",
       "      <td>129500.0</td>\n",
       "      <td>185000.0</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wyoming</th>\n",
       "      <td>5.0</td>\n",
       "      <td>29963.2</td>\n",
       "      <td>42500.0</td>\n",
       "      <td>50128.0</td>\n",
       "      <td>77016.0</td>\n",
       "      <td>123200.0</td>\n",
       "      <td>140000.0</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mississippi</th>\n",
       "      <td>25000.0</td>\n",
       "      <td>31100.0</td>\n",
       "      <td>37031.5</td>\n",
       "      <td>54000.0</td>\n",
       "      <td>82000.0</td>\n",
       "      <td>112000.0</td>\n",
       "      <td>130000.0</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Oklahoma</th>\n",
       "      <td>18000.0</td>\n",
       "      <td>27648.4</td>\n",
       "      <td>43236.0</td>\n",
       "      <td>54040.0</td>\n",
       "      <td>80000.0</td>\n",
       "      <td>141550.0</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>South Carolina</th>\n",
       "      <td>0.0</td>\n",
       "      <td>29178.5</td>\n",
       "      <td>43670.0</td>\n",
       "      <td>56750.0</td>\n",
       "      <td>78937.5</td>\n",
       "      <td>134950.0</td>\n",
       "      <td>5000000.0</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Maine</th>\n",
       "      <td>22000.0</td>\n",
       "      <td>34564.25</td>\n",
       "      <td>43125.0</td>\n",
       "      <td>57750.0</td>\n",
       "      <td>83000.0</td>\n",
       "      <td>114750.0</td>\n",
       "      <td>173000.0</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>North Dakota</th>\n",
       "      <td>0.0</td>\n",
       "      <td>27584.0</td>\n",
       "      <td>45000.0</td>\n",
       "      <td>59000.0</td>\n",
       "      <td>75000.0</td>\n",
       "      <td>110500.0</td>\n",
       "      <td>150000.0</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kentucky</th>\n",
       "      <td>0.0</td>\n",
       "      <td>29000.0</td>\n",
       "      <td>43441.0</td>\n",
       "      <td>59317.5</td>\n",
       "      <td>78000.0</td>\n",
       "      <td>130000.0</td>\n",
       "      <td>208000.0</td>\n",
       "      <td>192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alabama</th>\n",
       "      <td>0.0</td>\n",
       "      <td>20140.0</td>\n",
       "      <td>45000.0</td>\n",
       "      <td>59500.0</td>\n",
       "      <td>84750.0</td>\n",
       "      <td>164450.0</td>\n",
       "      <td>3600000.0</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Idaho</th>\n",
       "      <td>38.0</td>\n",
       "      <td>30960.0</td>\n",
       "      <td>46000.0</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>78000.0</td>\n",
       "      <td>130000.0</td>\n",
       "      <td>312000.0</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Arkansas</th>\n",
       "      <td>4.0</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>45880.0</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>87400.0</td>\n",
       "      <td>144500.0</td>\n",
       "      <td>488000.0</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>South Dakota</th>\n",
       "      <td>29000.0</td>\n",
       "      <td>31560.0</td>\n",
       "      <td>45750.0</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>66805.0</td>\n",
       "      <td>126800.0</td>\n",
       "      <td>150000.0</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vermont</th>\n",
       "      <td>24960.0</td>\n",
       "      <td>32550.0</td>\n",
       "      <td>50750.0</td>\n",
       "      <td>61000.0</td>\n",
       "      <td>84750.0</td>\n",
       "      <td>127250.0</td>\n",
       "      <td>200000.0</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kansas</th>\n",
       "      <td>52.0</td>\n",
       "      <td>33650.0</td>\n",
       "      <td>45125.0</td>\n",
       "      <td>61250.0</td>\n",
       "      <td>81000.0</td>\n",
       "      <td>125000.0</td>\n",
       "      <td>734400.0</td>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Iowa</th>\n",
       "      <td>13000.0</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>47840.0</td>\n",
       "      <td>62500.0</td>\n",
       "      <td>87000.0</td>\n",
       "      <td>122975.0</td>\n",
       "      <td>200000.0</td>\n",
       "      <td>179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Louisiana</th>\n",
       "      <td>17000.0</td>\n",
       "      <td>30272.0</td>\n",
       "      <td>47000.0</td>\n",
       "      <td>62500.0</td>\n",
       "      <td>85000.0</td>\n",
       "      <td>150000.0</td>\n",
       "      <td>253300.0</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hawaii</th>\n",
       "      <td>12000.0</td>\n",
       "      <td>31107.0</td>\n",
       "      <td>53250.0</td>\n",
       "      <td>62850.0</td>\n",
       "      <td>75000.0</td>\n",
       "      <td>123100.0</td>\n",
       "      <td>500000.0</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tennessee</th>\n",
       "      <td>20800.0</td>\n",
       "      <td>33028.0</td>\n",
       "      <td>47750.0</td>\n",
       "      <td>63000.0</td>\n",
       "      <td>85000.0</td>\n",
       "      <td>155800.0</td>\n",
       "      <td>657900.0</td>\n",
       "      <td>283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nebraska</th>\n",
       "      <td>18000.0</td>\n",
       "      <td>33144.5</td>\n",
       "      <td>46650.0</td>\n",
       "      <td>64000.0</td>\n",
       "      <td>86500.0</td>\n",
       "      <td>137500.0</td>\n",
       "      <td>224000.0</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Missouri</th>\n",
       "      <td>70.0</td>\n",
       "      <td>30560.0</td>\n",
       "      <td>47840.0</td>\n",
       "      <td>65000.0</td>\n",
       "      <td>94000.0</td>\n",
       "      <td>145000.0</td>\n",
       "      <td>335000.0</td>\n",
       "      <td>345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Indiana</th>\n",
       "      <td>105.0</td>\n",
       "      <td>33050.0</td>\n",
       "      <td>48825.0</td>\n",
       "      <td>65000.0</td>\n",
       "      <td>84752.5</td>\n",
       "      <td>134300.0</td>\n",
       "      <td>925000.0</td>\n",
       "      <td>328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>New Hampshire</th>\n",
       "      <td>55.0</td>\n",
       "      <td>30994.4</td>\n",
       "      <td>46600.0</td>\n",
       "      <td>65000.0</td>\n",
       "      <td>89250.0</td>\n",
       "      <td>142468.25</td>\n",
       "      <td>208000.0</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wisconsin</th>\n",
       "      <td>1.0</td>\n",
       "      <td>34000.0</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>66560.0</td>\n",
       "      <td>90000.0</td>\n",
       "      <td>146000.0</td>\n",
       "      <td>920000.0</td>\n",
       "      <td>471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Arizona</th>\n",
       "      <td>15.0</td>\n",
       "      <td>34000.0</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>66700.0</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>154900.0</td>\n",
       "      <td>380000.0</td>\n",
       "      <td>303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Florida</th>\n",
       "      <td>150.0</td>\n",
       "      <td>31200.0</td>\n",
       "      <td>47762.0</td>\n",
       "      <td>67000.0</td>\n",
       "      <td>97875.0</td>\n",
       "      <td>162950.0</td>\n",
       "      <td>2600000.0</td>\n",
       "      <td>522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Michigan</th>\n",
       "      <td>55.0</td>\n",
       "      <td>32000.0</td>\n",
       "      <td>52000.0</td>\n",
       "      <td>67500.0</td>\n",
       "      <td>90000.0</td>\n",
       "      <td>147638.4</td>\n",
       "      <td>500000.0</td>\n",
       "      <td>545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ohio</th>\n",
       "      <td>36.0</td>\n",
       "      <td>33000.0</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>67550.0</td>\n",
       "      <td>89753.75</td>\n",
       "      <td>150000.0</td>\n",
       "      <td>954000.0</td>\n",
       "      <td>658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>New Mexico</th>\n",
       "      <td>78.0</td>\n",
       "      <td>33892.0</td>\n",
       "      <td>52000.0</td>\n",
       "      <td>69000.0</td>\n",
       "      <td>107000.0</td>\n",
       "      <td>166800.0</td>\n",
       "      <td>300000.0</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pennsylvania</th>\n",
       "      <td>0.0</td>\n",
       "      <td>33067.5</td>\n",
       "      <td>52000.0</td>\n",
       "      <td>70250.0</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>165000.0</td>\n",
       "      <td>1100000.0</td>\n",
       "      <td>950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nevada</th>\n",
       "      <td>55.0</td>\n",
       "      <td>34449.4</td>\n",
       "      <td>52500.0</td>\n",
       "      <td>71000.0</td>\n",
       "      <td>95700.0</td>\n",
       "      <td>171500.0</td>\n",
       "      <td>425000.0</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rhode Island</th>\n",
       "      <td>18000.0</td>\n",
       "      <td>36210.0</td>\n",
       "      <td>52546.0</td>\n",
       "      <td>71500.0</td>\n",
       "      <td>95625.0</td>\n",
       "      <td>132150.0</td>\n",
       "      <td>200000.0</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alaska</th>\n",
       "      <td>27040.0</td>\n",
       "      <td>40000.0</td>\n",
       "      <td>55500.0</td>\n",
       "      <td>72400.0</td>\n",
       "      <td>91500.0</td>\n",
       "      <td>154750.0</td>\n",
       "      <td>10000000.0</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Utah</th>\n",
       "      <td>18720.0</td>\n",
       "      <td>34054.0</td>\n",
       "      <td>54087.5</td>\n",
       "      <td>72903.5</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>175550.0</td>\n",
       "      <td>576000.0</td>\n",
       "      <td>210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>North Carolina</th>\n",
       "      <td>4000.0</td>\n",
       "      <td>34535.9</td>\n",
       "      <td>51000.0</td>\n",
       "      <td>73000.0</td>\n",
       "      <td>98000.0</td>\n",
       "      <td>150000.0</td>\n",
       "      <td>560000.0</td>\n",
       "      <td>603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Georgia</th>\n",
       "      <td>0.0</td>\n",
       "      <td>32000.0</td>\n",
       "      <td>53000.0</td>\n",
       "      <td>75000.0</td>\n",
       "      <td>105000.0</td>\n",
       "      <td>173400.0</td>\n",
       "      <td>860000.0</td>\n",
       "      <td>537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Minnesota</th>\n",
       "      <td>40.0</td>\n",
       "      <td>39616.0</td>\n",
       "      <td>55000.0</td>\n",
       "      <td>75000.0</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>150000.0</td>\n",
       "      <td>321250.0</td>\n",
       "      <td>725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>New Jersey</th>\n",
       "      <td>14850.0</td>\n",
       "      <td>35000.0</td>\n",
       "      <td>57750.0</td>\n",
       "      <td>75000.0</td>\n",
       "      <td>104250.0</td>\n",
       "      <td>180050.0</td>\n",
       "      <td>5000044.0</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Colorado</th>\n",
       "      <td>65.0</td>\n",
       "      <td>38312.0</td>\n",
       "      <td>58000.0</td>\n",
       "      <td>76000.0</td>\n",
       "      <td>110750.0</td>\n",
       "      <td>165675.0</td>\n",
       "      <td>630000.0</td>\n",
       "      <td>634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Texas</th>\n",
       "      <td>0.0</td>\n",
       "      <td>35118.0</td>\n",
       "      <td>55000.0</td>\n",
       "      <td>76000.0</td>\n",
       "      <td>110000.0</td>\n",
       "      <td>175000.0</td>\n",
       "      <td>1200000.0</td>\n",
       "      <td>1271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Illinois</th>\n",
       "      <td>0.0</td>\n",
       "      <td>37440.0</td>\n",
       "      <td>56000.0</td>\n",
       "      <td>76000.0</td>\n",
       "      <td>110000.0</td>\n",
       "      <td>172240.0</td>\n",
       "      <td>1100000.0</td>\n",
       "      <td>1215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Oregon</th>\n",
       "      <td>0.0</td>\n",
       "      <td>36760.0</td>\n",
       "      <td>58000.0</td>\n",
       "      <td>78000.0</td>\n",
       "      <td>110000.0</td>\n",
       "      <td>185000.0</td>\n",
       "      <td>320000.0</td>\n",
       "      <td>633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Delaware</th>\n",
       "      <td>35000.0</td>\n",
       "      <td>40480.0</td>\n",
       "      <td>57546.5</td>\n",
       "      <td>80145.0</td>\n",
       "      <td>105500.0</td>\n",
       "      <td>163297.0</td>\n",
       "      <td>220000.0</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Virginia</th>\n",
       "      <td>57.0</td>\n",
       "      <td>37400.0</td>\n",
       "      <td>58750.0</td>\n",
       "      <td>81000.0</td>\n",
       "      <td>114059.0</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>1300000.0</td>\n",
       "      <td>801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Connecticut</th>\n",
       "      <td>0.0</td>\n",
       "      <td>33872.5</td>\n",
       "      <td>62000.0</td>\n",
       "      <td>82000.0</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>161500.0</td>\n",
       "      <td>1900000.0</td>\n",
       "      <td>238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Maryland</th>\n",
       "      <td>0.0</td>\n",
       "      <td>40450.0</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>82000.0</td>\n",
       "      <td>110000.0</td>\n",
       "      <td>165000.0</td>\n",
       "      <td>353200.0</td>\n",
       "      <td>570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Massachusetts</th>\n",
       "      <td>155.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>64000.0</td>\n",
       "      <td>86000.0</td>\n",
       "      <td>120000.0</td>\n",
       "      <td>181600.0</td>\n",
       "      <td>1650000.0</td>\n",
       "      <td>1525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>New York</th>\n",
       "      <td>80.0</td>\n",
       "      <td>40576.0</td>\n",
       "      <td>64581.25</td>\n",
       "      <td>90000.0</td>\n",
       "      <td>128000.0</td>\n",
       "      <td>210000.0</td>\n",
       "      <td>3000000.0</td>\n",
       "      <td>2182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>District of Columbia</th>\n",
       "      <td>40.0</td>\n",
       "      <td>48075.0</td>\n",
       "      <td>66800.0</td>\n",
       "      <td>90000.0</td>\n",
       "      <td>125000.0</td>\n",
       "      <td>188550.0</td>\n",
       "      <td>1334782.0</td>\n",
       "      <td>984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Washington</th>\n",
       "      <td>72.0</td>\n",
       "      <td>39860.0</td>\n",
       "      <td>65000.0</td>\n",
       "      <td>91000.0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>201700.0</td>\n",
       "      <td>1260000.0</td>\n",
       "      <td>1194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>California</th>\n",
       "      <td>0.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>72000.0</td>\n",
       "      <td>100260.0</td>\n",
       "      <td>147000.0</td>\n",
       "      <td>220000.0</td>\n",
       "      <td>875000.0</td>\n",
       "      <td>2613</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          0.0      0.05      0.25       0.5      0.75  \\\n",
       "state                                                                   \n",
       "West Virginia             0.0   27050.0   41250.0   49544.0   74100.0   \n",
       "Montana               19200.0   33631.0   37125.0   49700.0   84250.0   \n",
       "Wyoming                   5.0   29963.2   42500.0   50128.0   77016.0   \n",
       "Mississippi           25000.0   31100.0   37031.5   54000.0   82000.0   \n",
       "Oklahoma              18000.0   27648.4   43236.0   54040.0   80000.0   \n",
       "South Carolina            0.0   29178.5   43670.0   56750.0   78937.5   \n",
       "Maine                 22000.0  34564.25   43125.0   57750.0   83000.0   \n",
       "North Dakota              0.0   27584.0   45000.0   59000.0   75000.0   \n",
       "Kentucky                  0.0   29000.0   43441.0   59317.5   78000.0   \n",
       "Alabama                   0.0   20140.0   45000.0   59500.0   84750.0   \n",
       "Idaho                    38.0   30960.0   46000.0   60000.0   78000.0   \n",
       "Arkansas                  4.0   30000.0   45880.0   60000.0   87400.0   \n",
       "South Dakota          29000.0   31560.0   45750.0   60000.0   66805.0   \n",
       "Vermont               24960.0   32550.0   50750.0   61000.0   84750.0   \n",
       "Kansas                   52.0   33650.0   45125.0   61250.0   81000.0   \n",
       "Iowa                  13000.0   30000.0   47840.0   62500.0   87000.0   \n",
       "Louisiana             17000.0   30272.0   47000.0   62500.0   85000.0   \n",
       "Hawaii                12000.0   31107.0   53250.0   62850.0   75000.0   \n",
       "Tennessee             20800.0   33028.0   47750.0   63000.0   85000.0   \n",
       "Nebraska              18000.0   33144.5   46650.0   64000.0   86500.0   \n",
       "Missouri                 70.0   30560.0   47840.0   65000.0   94000.0   \n",
       "Indiana                 105.0   33050.0   48825.0   65000.0   84752.5   \n",
       "New Hampshire            55.0   30994.4   46600.0   65000.0   89250.0   \n",
       "Wisconsin                 1.0   34000.0   50000.0   66560.0   90000.0   \n",
       "Arizona                  15.0   34000.0   50000.0   66700.0  100000.0   \n",
       "Florida                 150.0   31200.0   47762.0   67000.0   97875.0   \n",
       "Michigan                 55.0   32000.0   52000.0   67500.0   90000.0   \n",
       "Ohio                     36.0   33000.0   50000.0   67550.0  89753.75   \n",
       "New Mexico               78.0   33892.0   52000.0   69000.0  107000.0   \n",
       "Pennsylvania              0.0   33067.5   52000.0   70250.0  100000.0   \n",
       "Nevada                   55.0   34449.4   52500.0   71000.0   95700.0   \n",
       "Rhode Island          18000.0   36210.0   52546.0   71500.0   95625.0   \n",
       "Alaska                27040.0   40000.0   55500.0   72400.0   91500.0   \n",
       "Utah                  18720.0   34054.0   54087.5   72903.5  100000.0   \n",
       "North Carolina         4000.0   34535.9   51000.0   73000.0   98000.0   \n",
       "Georgia                   0.0   32000.0   53000.0   75000.0  105000.0   \n",
       "Minnesota                40.0   39616.0   55000.0   75000.0  100000.0   \n",
       "New Jersey            14850.0   35000.0   57750.0   75000.0  104250.0   \n",
       "Colorado                 65.0   38312.0   58000.0   76000.0  110750.0   \n",
       "Texas                     0.0   35118.0   55000.0   76000.0  110000.0   \n",
       "Illinois                  0.0   37440.0   56000.0   76000.0  110000.0   \n",
       "Oregon                    0.0   36760.0   58000.0   78000.0  110000.0   \n",
       "Delaware              35000.0   40480.0   57546.5   80145.0  105500.0   \n",
       "Virginia                 57.0   37400.0   58750.0   81000.0  114059.0   \n",
       "Connecticut               0.0   33872.5   62000.0   82000.0  100000.0   \n",
       "Maryland                  0.0   40450.0   60000.0   82000.0  110000.0   \n",
       "Massachusetts           155.0   42000.0   64000.0   86000.0  120000.0   \n",
       "New York                 80.0   40576.0  64581.25   90000.0  128000.0   \n",
       "District of Columbia     40.0   48075.0   66800.0   90000.0  125000.0   \n",
       "Washington               72.0   39860.0   65000.0   91000.0  135000.0   \n",
       "California                0.0   42000.0   72000.0  100260.0  147000.0   \n",
       "\n",
       "                           0.95         1.0  count  \n",
       "state                                               \n",
       "West Virginia          117465.2    125000.0     42  \n",
       "Montana                129500.0    185000.0     66  \n",
       "Wyoming                123200.0    140000.0     29  \n",
       "Mississippi            112000.0    130000.0     51  \n",
       "Oklahoma               141550.0    180000.0    114  \n",
       "South Carolina         134950.0   5000000.0    150  \n",
       "Maine                  114750.0    173000.0    126  \n",
       "North Dakota           110500.0    150000.0     35  \n",
       "Kentucky               130000.0    208000.0    192  \n",
       "Alabama                164450.0   3600000.0    122  \n",
       "Idaho                  130000.0    312000.0     97  \n",
       "Arkansas               144500.0    488000.0     71  \n",
       "South Dakota           126800.0    150000.0     25  \n",
       "Vermont                127250.0    200000.0     72  \n",
       "Kansas                 125000.0    734400.0    154  \n",
       "Iowa                   122975.0    200000.0    179  \n",
       "Louisiana              150000.0    253300.0    129  \n",
       "Hawaii                 123100.0    500000.0     30  \n",
       "Tennessee              155800.0    657900.0    283  \n",
       "Nebraska               137500.0    224000.0    111  \n",
       "Missouri               145000.0    335000.0    345  \n",
       "Indiana                134300.0    925000.0    328  \n",
       "New Hampshire         142468.25    208000.0    120  \n",
       "Wisconsin              146000.0    920000.0    471  \n",
       "Arizona                154900.0    380000.0    303  \n",
       "Florida                162950.0   2600000.0    522  \n",
       "Michigan               147638.4    500000.0    545  \n",
       "Ohio                   150000.0    954000.0    658  \n",
       "New Mexico             166800.0    300000.0     98  \n",
       "Pennsylvania           165000.0   1100000.0    950  \n",
       "Nevada                 171500.0    425000.0     95  \n",
       "Rhode Island           132150.0    200000.0     78  \n",
       "Alaska                 154750.0  10000000.0     66  \n",
       "Utah                   175550.0    576000.0    210  \n",
       "North Carolina         150000.0    560000.0    603  \n",
       "Georgia                173400.0    860000.0    537  \n",
       "Minnesota              150000.0    321250.0    725  \n",
       "New Jersey             180050.0   5000044.0    400  \n",
       "Colorado               165675.0    630000.0    634  \n",
       "Texas                  175000.0   1200000.0   1271  \n",
       "Illinois               172240.0   1100000.0   1215  \n",
       "Oregon                 185000.0    320000.0    633  \n",
       "Delaware               163297.0    220000.0     47  \n",
       "Virginia               180000.0   1300000.0    801  \n",
       "Connecticut            161500.0   1900000.0    238  \n",
       "Maryland               165000.0    353200.0    570  \n",
       "Massachusetts          181600.0   1650000.0   1525  \n",
       "New York               210000.0   3000000.0   2182  \n",
       "District of Columbia   188550.0   1334782.0    984  \n",
       "Washington             201700.0   1260000.0   1194  \n",
       "California             220000.0    875000.0   2613  "
      ]
     },
     "execution_count": 496,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_sorted"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
